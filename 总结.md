---
title: 总结
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---
---
### <center>引言</center>
&emsp; 在这一段时间里面，我在有关深度学习的知识上面取得了一定的进步。从第一次去和张新良老师交流，到现在我着手开始写这个总结，我从基本的卷积神经网络出发，先使用基本的卷积神经网络对精确的单张人脸进行识别，再在多个人脸共存的环境中对人脸进行检测，实现了多张人脸同步识别。再从物体检测识别的方向出发，对于工业应用场景里面的物体进行检测识别并定位，再将这些数据传给程序控制的机械手臂，达到工业场景下的智能分拣的效果。
### <center>主要内容</center>
#### 1.基本CNN进行人脸识别的学习应用
##### 1.1传统机器学习
&emsp;在基本的机器学习的做法中，我们往往是使用一些人工给定的特征来进行算法学习，就二分类问题下的逻辑回归来说，我们使用现有的特征去形成一个可知的模型，然后利用均方误差、平均绝对值等构成模型的损失函数，损失函数对于参数求偏导之后便可以对于参数进行凸优化进行机器学习训练，最后形成一个可用的模型，具体做法可见我的博客[逻辑回归算法浅析及其Python实现](https://blog.csdn.net/qq_36782182/article/details/85009739)，此类机器学习的方法也被应用在了大量的现实问题处理中。但是传统的机器学习算法在图像识别等复杂工作上面却无法表现的更好。
&emsp;在2012年的卷积神经网络算法AlexNet以大幅度领先超越传统机器学习算法获得ImageNet竞赛冠军之后，卷积神经网络在图像问题上面的可行性就被广泛认知了。
##### 1.2卷积神经网络
对于一张256\*256的图像来说，它上面的像素点就是256×256个，可以形成一个256×256的矩阵：
$$\begin{bmatrix}
x_1^1&x_2^1&{\cdots}&x_{256}^1\\
x_1^2&x_2^2&{\cdots}&x_1^2\\
{\vdots}&{\vdots}&{\ddots}&{\vdots}\\
x_1^{256}&x_1^2&{\cdots}&x_{256}^{256}\\
\end{bmatrix}=X_1$$
另外，为了从图像里面提取特征，我们需要对于这个矩阵的一些卷积核，如果我们拥有一个大小为3×3的卷积核的话：
$$\begin{bmatrix}
\theta_1^1&\theta_2^1&\theta_3^1\\
\theta_1^2&\theta_2^2&\theta_3^2\\
\theta_1^3&\theta_2^3&\theta_3^3\\
\end{bmatrix}=\Theta_1$$
那么我们使用这个卷积核对$X$矩阵的子矩阵$x_1^1\sim{}x_3^3$进行卷积运算，便可以得到基于这个卷积核的一个特征值，同时我们还可以拥有多个$\Theta$,在我们用卷积核对原始图像进行卷积时，我们可以先对左上角进行卷积、再向右移动一格，再次进行卷积，在第一层卷积之后，我们再将卷积核往下移动一格，按照第一层的方式再进行卷积，在用单一3×3卷积核对一张256×256的图像进行卷积之后，我们可以得到一个253×253的特征矩阵，如果我们有n个卷积核的话，那么我们就会有n个特征矩阵，再将这些特征矩阵中的特征值输入到一个全连接层，也就是：
$$f(x)=\sum_{i=1}^{n*256*256}\omega_{i}x_i（这里的x指的是随机排列的全部特征值）$$
